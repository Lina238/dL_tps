{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DScS_G9eTX3w"
      },
      "outputs": [],
      "source": [
        "# TP - Classification d'Expressions Faciales avec CNN\n",
        "\n",
        "# Étape 1 : Vérification GPU et Imports\n",
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.model_selection\n",
        "import sklearn.metrics\n",
        "import sklearn.utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Vérification GPU\n",
        "print(\"GPU disponible :\", tf.test.is_gpu_available())\n",
        "\n",
        "# Étape 2 : Chargement des données\n",
        "def load_data(csv_path, images_dir):\n",
        "    \"\"\"\n",
        "    Charger les images et les labels à partir d'un fichier CSV\n",
        "\n",
        "    Args:\n",
        "    - csv_path: Chemin vers le fichier CSV des labels\n",
        "    - images_dir: Répertoire contenant les images\n",
        "\n",
        "    Returns:\n",
        "    - images: Tableau numpy des images\n",
        "    - labels: Tableau numpy des labels\n",
        "    \"\"\"\n",
        "    # Lecture du CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Préparation des listes pour stocker images et labels\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Parcours du dataframe\n",
        "    for index, row in df.iterrows():\n",
        "        # Chemin complet de l'image\n",
        "        img_path = os.path.join(images_dir, row['filename'])\n",
        "\n",
        "        # Charger l'image en niveaux de gris et redimensionner\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (48, 48))  # Taille standard pour les CNN\n",
        "            images.append(img)\n",
        "            labels.append(row['emotion'])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Charger les données\n",
        "images_dir = 'facial_expressions/data/images'\n",
        "csv_path = 'facial_expressions/data/legend.csv'\n",
        "images, labels = load_data(csv_path, images_dir)\n",
        "\n",
        "# Étape 3 : Exploration du dataset\n",
        "# Distribution des classes\n",
        "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(unique_labels, label_counts)\n",
        "plt.title('Distribution des Classes')\n",
        "plt.xlabel('Émotions')\n",
        "plt.ylabel('Nombre d\\'images')\n",
        "plt.show()\n",
        "\n",
        "# Affichage de quelques images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(images[i], cmap='gray')\n",
        "    plt.title(f'Émotion: {labels[i]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Prétraitement des données\n",
        "# Normalisation et reshape\n",
        "images = images.reshape(-1, 48, 48, 1) / 255.0\n",
        "\n",
        "# Encodage one-hot des labels\n",
        "labels = keras.utils.to_categorical(labels)\n",
        "\n",
        "# Séparation train/test\n",
        "train_images, test_images, train_labels, test_labels = (\n",
        "    sklearn.model_selection.train_test_split(\n",
        "        images, labels, test_size=0.2, stratify=np.argmax(labels, axis=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Construction du modèle CNN\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = keras.Sequential([\n",
        "        # Première couche de convolution\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Deuxième couche de convolution\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Troisième couche de convolution\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Couche de flattening\n",
        "        keras.layers.Flatten(),\n",
        "\n",
        "        # Couches fully connected\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "\n",
        "        # Couche de sortie\n",
        "        keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Création du modèle\n",
        "model = create_cnn_model((48, 48, 1), num_classes=labels.shape[1])\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Calcul des poids de classe\n",
        "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(np.argmax(labels, axis=1)),\n",
        "    y=np.argmax(labels, axis=1)\n",
        ")\n",
        "\n",
        "# Clip des poids de classe\n",
        "class_weights = np.clip(class_weights, 0, 5)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Évaluation du modèle\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Prédictions\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Matrice de confusion\n",
        "cm = sklearn.metrics.confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matrice de Confusion')\n",
        "plt.xlabel('Prédictions')\n",
        "plt.ylabel('Vraies Classes')\n",
        "plt.show()\n",
        "\n",
        "# Courbes d'apprentissage\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}